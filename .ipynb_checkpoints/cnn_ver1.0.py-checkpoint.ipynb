{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick cnn coded in tensorflow, via some wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/matthew/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import data and modules\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST('./data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = data.num_train\n",
    "num_test = data.num_test\n",
    "img_size = data.img_size\n",
    "num_classes = data.num_classes\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train\n",
    "num_test\n",
    "img_size\n",
    "num_classes\n",
    "num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn architecture\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape))\n",
    "\n",
    "def new_biases(length):\n",
    "    \n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "    \n",
    "    return biases\n",
    "\n",
    "def new_conv_layer(input, filter_size, num_inputs, num_filters, stride_step, pool_step, use_pooling):\n",
    "    \n",
    "    filter_shape = [filter_size, filter_size, num_inputs, num_filters]\n",
    "    \n",
    "    weights = new_weights(filter_shape)\n",
    "    biases = new_biases(num_filters)\n",
    "    layer = tf.nn.conv2d(input=input, \n",
    "                         filter=weights,\n",
    "                         strides=[1, stride_step, stride_step, 1],\n",
    "                         padding='SAME')\n",
    "    \n",
    "    layer = layer + biases\n",
    "    \n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(layer, [1, 2, 2, 1], strides=[1, pool_step, pool_step, 1], padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def flatten_layer(input):\n",
    "\n",
    "    input_shape = input.get_shape()\n",
    "    num_features = input_shape[1:4].num_elements()\n",
    "    layer = tf.reshape(input, [-1, num_features], name='flatten_layer')\n",
    "        \n",
    "    return layer, num_features\n",
    "\n",
    "def new_fc_layer(input, num_inputs, num_outputs):\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[num_inputs, num_outputs]))\n",
    "    biases = tf.Variable(tf.constant(0.005, shape=[num_outputs]))\n",
    "    \n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    return layer\n",
    "    \n",
    "def new_dropout_layer(input, rate, training_bool_flag):\n",
    "    \n",
    "    layer = tf.layers.dropout(input=input, rate=rate, training=training_bool_flag)\n",
    "    \n",
    "    return layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders for data \n",
    "img_size_flat = img_size*img_size*num_channels\n",
    "x_flat_img = tf.placeholder(dtype=tf.float32, shape=[None, img_size_flat])\n",
    "x = tf.reshape(x_flat_img, shape=[-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=[None, num_classes])\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size1 = 3\n",
    "num_filters1 = 16\n",
    "\n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "fc_size1 = 128\n",
    "\n",
    "conv1 = new_conv_layer(input=x, filter_size=filter_size1, num_inputs=num_channels, num_filters=num_filters1, \n",
    "                       stride_step=1, pool_step=2, use_pooling=True)\n",
    "conv2 = new_conv_layer(input=conv1, filter_size=filter_size2, \n",
    "                       num_inputs=num_filters1, num_filters=num_filters2, \n",
    "                       stride_step=1, pool_step=2, use_pooling=True)\n",
    "\n",
    "flat_layer1, flat_layer1_features = flatten_layer(conv2)\n",
    "\n",
    "fc1 = new_fc_layer(input=flat_layer1, num_inputs=flat_layer1_features, num_outputs=fc_size1)\n",
    "logits = new_fc_layer(input=fc1, num_inputs=fc_size1, num_outputs=num_classes)\n",
    "\n",
    "ypred = tf.nn.softmax(logits=logits)\n",
    "ypred_cls = tf.argmax(ypred, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer \n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "# import ipdb; ipdb.set_trace()\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.get_shape()\n",
    "y_true.get_shape()\n",
    "cost.get_shape()\n",
    "loss.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance measures\n",
    "correct_mask= tf.equal(ypred_cls, y_true_cls)\n",
    "acc = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations=1):\n",
    "    x_batch, y_true_batch, _ = data.random_batch(batch_size)\n",
    "    \n",
    "    feed_dict_train = {x_flat_img: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "    for i in range(num_iterations):\n",
    "        _, accuracy = sess.run([optimizer, acc], feed_dict=feed_dict_train)\n",
    "        if (i%100==0):\n",
    "            msg = \"accuracy: {0:6.1%}\"\n",
    "            print(msg.format(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   4.7%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n",
      "accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
